{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP assignment 4",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWMA27opuEOv"
      },
      "source": [
        "**Muhammad Mohsin**\n",
        "\n",
        "**i170216@nu.edu.pk**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDUAj5BvbaOH"
      },
      "source": [
        "MOUNTING DRIVE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd9h6-3wFnoT",
        "outputId": "c52c4fb7-2e2e-42cf-a448-f0fa3d2c9130"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY6ZxKYqm5Kt"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE39vkgZmi9m"
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict \n",
        "import re"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNlK1_aGbf16"
      },
      "source": [
        "READING FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt2a5naJFwUQ"
      },
      "source": [
        "#=====================================================================FILE READING===============================================================\n",
        "def readFile(file_loc): \n",
        "  file1 = open(file_loc, 'r')\n",
        "  Lines = file1.readlines()\n",
        "  \n",
        "  rawData = []\n",
        "  count = 0\n",
        "  # Strips the newline character\n",
        "  for line in Lines: \n",
        "    line = line.strip() \n",
        "    if line == \"\\n\" or line == '': \n",
        "      pass\n",
        "    else:\n",
        "      rawData.append(line)  \n",
        "\n",
        "  return rawData \n",
        "\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9q2V8qwbpa1"
      },
      "source": [
        "TOKENZING THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_p80NZnFyNt"
      },
      "source": [
        "#===================================================================== TOKENIZING ===============================================================\n",
        "#FOR CHARACHTER BIGRAM & UNIGRAM MODEL \n",
        "def char_tokenize(rawData): \n",
        "  tokenz = []\n",
        "  for line in rawData: \n",
        "    token = line.split() \n",
        "    for word in token:  \n",
        "      tokenz.append(word)\n",
        "  return tokenz\n",
        "\n",
        " \n",
        "  "
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1SocfCbbv7z"
      },
      "source": [
        "CREATING CHARACTER LEVEL BIGRAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMFAkz26bleU"
      },
      "source": [
        "def generate_character_bigram(char_tokenz): \n",
        "  bigram = []\n",
        "  c_bigram = [] \n",
        "  ngram = defaultdict(int)\n",
        "  for i in range(0, len(char_tokenz)): \n",
        "    for j in range(0, len(char_tokenz[i])-1): \n",
        "      ngram[char_tokenz[i][j] + char_tokenz[i][j+1]] +=1\n",
        "  \n",
        "  for w,c in ngram.items(): \n",
        "    bigram.append(w) \n",
        "    c_bigram.append(c) \n",
        "    \n",
        "  return bigram,c_bigram \n",
        " "
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewg_kKW0b3ue"
      },
      "source": [
        "CREATING UNIGRAMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zbyBENKzYaG"
      },
      "source": [
        "def generate_unigram(ngram_token):\n",
        "  unigram = defaultdict(int)\n",
        "  for word in ngram_token:\n",
        "    unigram[word] += 1 # increment element's value by 1\n",
        "  return unigram"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JWq8sHOb6ml"
      },
      "source": [
        "READING MISSPELLING.TXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t-gmkJSZqpR"
      },
      "source": [
        "#=====================================================================FILE READING===============================================================\n",
        "def read_Mispelled(file_loc): \n",
        "  file1 = open(file_loc, 'r')\n",
        "  Lines = file1.readlines()\n",
        "  \n",
        "  rawData = []\n",
        "  count = 0\n",
        "  # Strips the newline character\n",
        "  for line in Lines: \n",
        "    line = line.strip()  \n",
        "    if count == 0:  \n",
        "      count+=1; \n",
        "      pass \n",
        "    else:\n",
        "      count+=1 \n",
        "      if line == \"\\n\" or line == '': \n",
        "        pass\n",
        "      else:\n",
        "        rawData.append(line)   \n",
        "\n",
        "  for i in range(len(rawData)):    \n",
        "    rawData[i] = re.split(' |,|\\*|\\t',rawData[i]) \n",
        "    while '' in rawData[i]:\n",
        "      rawData[i].remove('')\n",
        "    \n",
        "  \n",
        "  return rawData \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz3ERlgPeL9r"
      },
      "source": [
        "Error Model Edit Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIJD4vm8GOHd"
      },
      "source": [
        "def createTable(misspelled): \n",
        "  #OPERATIONS \n",
        "  #1 : Insert\n",
        "  #2 : Delete \n",
        "  #3 : Subsiture \n",
        "  #4 : Traversal \n",
        "\n",
        "  delete = np.zeros((27, 26)) \n",
        "  insert = np.zeros((27, 26)) \n",
        "  subsitute = np.zeros((26, 26)) \n",
        "  traversal = np.zeros((26, 26))\n",
        "  \n",
        "  for i in range (0, len(misspelled)): \n",
        "    correct = misspelled[i][0]  \n",
        "    \n",
        "    for j in range(1, len(misspelled[i])):   \n",
        "      wrong  = misspelled[i][j] \n",
        "      if len(wrong)> len(correct): # YANI INSERT HO RHA HAI   \n",
        "        temp_corrected = correct # cz change karna hai\n",
        "        temp_corrected+='.' \n",
        "        for k in range(0,len(wrong)):        #loop to iterate the word   \n",
        "          if(wrong[k] != temp_corrected[k]):  \n",
        "            if k!= 0:  \n",
        "              idx_i = ord(correct[k-1]) - 97 \n",
        "              idx_j = ord(wrong[k]) - 97 \n",
        "              insert[idx_i][idx_j] += 1\n",
        "              break\n",
        "            else: \n",
        "              idx_j = ord(wrong[k]) - 97 \n",
        "              insert[26][idx_j] +=1 \n",
        "              break\n",
        "\n",
        "\n",
        "      elif len(correct)> len(wrong): #YANI DELETION HO RHI HAI  \n",
        "        temp_wrong = wrong # cz change karna hai\n",
        "        temp_wrong+= '.' \n",
        "        for k in range(len(correct)):       #loop to iterate the word  \n",
        "          if(temp_wrong[k] != correct[k]):  \n",
        "            if k!= 0:  \n",
        "              idx_i = ord(correct[k-1]) - 97 \n",
        "              idx_j = ord(correct[k]) - 97 \n",
        "              delete[idx_i][idx_j] += 1 \n",
        "              break\n",
        "            else: \n",
        "              idx_j = ord(correct[k]) - 97  \n",
        "              delete[26][idx_j] +=1 \n",
        "              break\n",
        "      \n",
        "       \n",
        "      elif len(correct) == len(wrong): #YANI SUBSITUTION ya TRAVERSAL HO RHa HAI \n",
        "        if (wrong[len(wrong)-1] != correct[len(correct)-1] and  wrong[len(wrong)-2] == correct[len(correct)-2] ): \n",
        "          idx_i = ord(wrong[len(wrong)-1]) - 97 \n",
        "          idx_j = ord(correct[len(correct)-1]) - 97  \n",
        "          subsitute[idx_i][idx_j] += 1\n",
        "        else: \n",
        "          for k in range(len(correct)-1):       #loop to iterate the word  \n",
        "            if wrong[k] != correct[k]: \n",
        "              if wrong[k+1] == correct[k] and wrong[k] == correct[k+1]: #to check traversal  \n",
        "                idx_i = ord(correct[k]) - 97 \n",
        "                idx_j = ord(correct[k+1]) - 97  \n",
        "                traversal[idx_i][idx_j] += 1 \n",
        "                break\n",
        "              else:  #warna subsiture hoga\n",
        "                idx_i = ord(wrong[k]) - 97 \n",
        "                idx_j = ord(correct[k]) - 97  \n",
        "                subsitute[idx_i][idx_j] += 1\n",
        "                break  \n",
        "\n",
        "  return insert, delete, subsitute, traversal\n",
        "  \n",
        "\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goOIrs2zeatd"
      },
      "source": [
        "Finding **P(X|W)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfdc3eoqG4vS"
      },
      "source": [
        "def find_Prob_X_given_W(insert, delete, subsitute, traversal, correct, wrong, bigram, bigram_count):\n",
        "  #INSERTION \n",
        "  if len(wrong)> len(correct): # YANI INSERT HO RHA HAI   \n",
        "    temp_corrected = correct # cz change karna hai\n",
        "    temp_corrected+='.' \n",
        "    for k in range(0,len(wrong)):        #loop to iterate the word   \n",
        "      if(wrong[k] != temp_corrected[k]):  \n",
        "        if k!= 0:  \n",
        "          idx_i = ord(correct[k-1]) - 97 \n",
        "          idx_j = ord(wrong[k]) - 97 \n",
        "          row_sum = np.sum(insert, axis = 1)   \n",
        "          denominator = row_sum[idx_i]\n",
        "          numerator = insert[idx_i][idx_j]\n",
        "          return numerator/ denominator  \n",
        "        else: \n",
        "          idx_i = 26\n",
        "          idx_j = ord(wrong[k]) - 97 \n",
        "          insert[idx_i][idx_j] +=1 \n",
        "          row_sum = np.sum(insert, axis = 1)   \n",
        "          denominator = row_sum[idx_i]\n",
        "          numerator = insert[idx_i][idx_j]\n",
        "          return numerator/ denominator  \n",
        "  \n",
        "  #DELETION\n",
        "  elif len(correct)> len(wrong): #YANI DELETION HO RHI HAI  \n",
        "      temp_wrong = wrong # cz change karna hai\n",
        "      temp_wrong+= '.' \n",
        "      for k in range(len(correct)):       #loop to iterate the word  \n",
        "        if(temp_wrong[k] != correct[k]):  \n",
        "          if k!= 0:  \n",
        "            idx_i = ord(correct[k-1]) - 97 \n",
        "            idx_j = ord(correct[k]) - 97 \n",
        "            bigram_char = correct[k-1] + correct[k] \n",
        "             \n",
        "            denominator = count_bigram[bigram.index(bigram_char)] \n",
        "            if denominator == 0:  \n",
        "              denominator = 100000\n",
        "            numerator = delete[idx_i][idx_j]\n",
        "            return numerator/ denominator\n",
        "          \n",
        "          else: \n",
        "            idx_i = 26 \n",
        "            idx_j = ord(correct[k]) - 97  \n",
        "            bigram_char = correct[k-1] + correct[k] \n",
        "            denominator = count_bigram[bigram.index(bigram_char)] \n",
        "            if denominator == 0: \n",
        "              denominator = 100000\n",
        "            numerator = delete[idx_i][idx_j]\n",
        "            return numerator/ denominator   \n",
        "  \n",
        "  #TRAVERSAL AND SUBSITUTION \n",
        "  elif len(correct) == len(wrong): #YANI SUBSITUTION ya TRAVERSAL HO RHa HAI \n",
        "    if (wrong[len(wrong)-1] != correct[len(correct)-1] and  wrong[len(wrong)-2] == correct[len(correct)-2] ): \n",
        "      idx_i = ord(wrong[len(wrong)-1]) - 97 \n",
        "      idx_j = ord(correct[len(correct)-1]) - 97  \n",
        "      col_sum = np.sum(insert, axis = 0)   \n",
        "      denominator = col_sum[idx_j]\n",
        "      numerator = subsitute[idx_i][idx_j] \n",
        "      return numerator/ denominator\n",
        "    else:\n",
        "      for k in range(len(correct)-1):       #loop to iterate the word  \n",
        "        if wrong[k] != correct[k]: \n",
        "          if wrong[k+1] == correct[k] and wrong[k] == correct[k+1]: #to check traversal  \n",
        "            idx_i = ord(correct[k]) - 97 \n",
        "            idx_j = ord(correct[k+1]) - 97  \n",
        "            bigram_char = correct[k] + correct[k+1]    \n",
        "            denominator = count_bigram[bigram.index(bigram_char)] \n",
        "            if denominator == 0: \n",
        "              denominator = 10000\n",
        "            numerator = traversal[idx_i][idx_j]\n",
        "            return numerator/ denominator \n",
        "          else:  #warna subsiture hoga\n",
        "            idx_i = ord(wrong[k]) - 97 \n",
        "            idx_j = ord(correct[k]) - 97  \n",
        "            col_sum = np.sum(insert, axis = 0)   \n",
        "            denominator = col_sum[idx_j]\n",
        "            numerator = subsitute[idx_i][idx_j]\n",
        "            return numerator/ denominator  \n",
        "          "
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgbjmRmmelx6"
      },
      "source": [
        "Check the word has traversal or not\n",
        "\n",
        "e.g\n",
        "\n",
        "correct: cares\n",
        "\n",
        "wrong: acres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKvjALi0g2F0"
      },
      "source": [
        "def hasTraversal(wrong, correct): \n",
        "  wrong_unigram = []  \n",
        "  wrong_unigram_count = [] \n",
        "  correct_unigram = []  \n",
        "  correct_unigram_count = []  \n",
        "\n",
        "  for i in range(0, len(wrong)):\n",
        "    if wrong[i] not in wrong_unigram:\n",
        "      wrong_unigram.append(wrong[i])\n",
        "      wrong_unigram_count.append(1)\n",
        "    else:\n",
        "      wrong_unigram_count[wrong_unigram.index(wrong[i])] +=1 \n",
        "      \n",
        "    if correct[i] not in correct_unigram:\n",
        "      correct_unigram.append(correct[i])\n",
        "      correct_unigram_count.append(1)\n",
        "    else:\n",
        "      correct_unigram_count[correct_unigram.index(correct[i])] +=1  \n",
        "  \n",
        "  traversal = True \n",
        "  if len(correct_unigram) != len(wrong_unigram): \n",
        "    return False\n",
        "  else:  \n",
        "    for i in range(len(correct_unigram)): \n",
        "      if correct_unigram[i] not in wrong_unigram: \n",
        "        traversal = False \n",
        "        return False\n",
        "      elif wrong_unigram_count[wrong_unigram.index(correct_unigram[i])] != correct_unigram_count[i] : \n",
        "        traversal = False \n",
        "        return False \n",
        "\n",
        "  for k in range(len(wrong)-1): \n",
        "    if wrong[k] != correct[k]: \n",
        "      if wrong[k+1] == correct[k] and wrong[k] == correct[k+1]: #to check traversal    \n",
        "          return True\n",
        "  \n",
        "  return False\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8TkStsUeqEp"
      },
      "source": [
        "Generating Candidate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWhy9d9Pf0Sl"
      },
      "source": [
        "import nltk\n",
        "def generate_candidates(misspell, unigram): \n",
        "  candidates = []\n",
        "  for word,_ in unigram.items():\n",
        "    edit_distance = nltk.edit_distance(misspell,word, substitution_cost=1)    \n",
        "    if edit_distance == 1: \n",
        "      candidates.append(word) \n",
        "    elif edit_distance == 2: \n",
        "      if len(word) == len(misspell): \n",
        "        if hasTraversal(word, misspell)== True: \n",
        "          candidates.append(word)\n",
        "\n",
        "  return candidates \n",
        "\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkNtpjHSeuj9"
      },
      "source": [
        "Finding the most Probable word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dplw9szi1UGF"
      },
      "source": [
        "def get_most_probable(candidates, misspell, insert, delete, subsitute, traversal, bigram, count_bigram, unigram):    \n",
        "  probabilities = []\n",
        "  for word in candidates:   \n",
        "    P_X_W = find_Prob_X_given_W(insert, delete, subsitute, traversal, word, misspell, bigram, count_bigram)   \n",
        "    P_W  = 0 \n",
        "    for w,c in unigram.items(): \n",
        "      if w == word: \n",
        "        P_W = c\n",
        "        break \n",
        "    prob = P_X_W * P_W  \n",
        "    probabilities.append(prob)\n",
        "\n",
        "  correct_word = candidates[np.argmax(probabilities)] \n",
        "  print(\"Word:\", misspell)  \n",
        "  print(\"Candidate Word with probability\")\n",
        "  for i in range(len(candidates)): \n",
        "    print(candidates[i], probabilities[i])\n",
        "  print(\"The most probable word is\", correct_word)  \n",
        "  print(\"\\n\")\n",
        "  return correct_word\n",
        "\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PurmS_0ht_3a"
      },
      "source": [
        "Check the word is misspelled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK4_A1BpqPwg"
      },
      "source": [
        "def isMisspelled(unigram, misspell): \n",
        "  for word in unigram: \n",
        "    if word == misspell: \n",
        "      return False\n",
        "  return True"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Sd1tFZeyjL"
      },
      "source": [
        "DRIVER CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naMV1U1F4AuB"
      },
      "source": [
        "rawData = readFile(\"/content/drive/MyDrive/NLP4/data.txt\")  \n",
        "char_tokenz = char_tokenize(rawData) "
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShMjf_NO4A33"
      },
      "source": [
        "unigram = generate_unigram(char_tokenz)\n",
        "bigram,count_bigram = generate_character_bigram(char_tokenz) "
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "594m747I4A7K"
      },
      "source": [
        "import numpy as np \n",
        "misspelled = read_Mispelled(\"/content/drive/MyDrive/NLP4/misspellings.txt\") \n",
        "insert, delete, subsitute, traversal = createTable(misspelled) \n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmO703eVrE68"
      },
      "source": [
        "EXAMPLE 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR_6BMlY3cW5",
        "outputId": "7b726cda-f6e0-4779-e677-c937c7374daa"
      },
      "source": [
        "wrong_word = \"terhuan\"\n",
        "\n",
        "if isMisspelled(unigram, wrong_word): \n",
        "  candidates = generate_candidates(wrong_word, unigram)\n",
        "  get_most_probable(candidates, wrong_word, insert, delete, subsitute, traversal, bigram, count_bigram, unigram)\n",
        "else: \n",
        "  print(\"Word is correctly spelled\")"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word: terhuan\n",
            "Candidate Word with probability\n",
            "terhan 15540.59315995725\n",
            "The most probable word is terhan\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5w9qN5KrIFo"
      },
      "source": [
        "EXAMPLE 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GnEJ6qJodSW",
        "outputId": "cffcfcb7-c1a3-43d3-9726-7c1f917b7907"
      },
      "source": [
        "wrong_word = \"satjh\"\n",
        "\n",
        "if isMisspelled(unigram, wrong_word): \n",
        "  candidates = generate_candidates(wrong_word, unigram)\n",
        "  get_most_probable(candidates, wrong_word, insert, delete, subsitute, traversal, bigram, count_bigram, unigram)\n",
        "else: \n",
        "  print(\"word is correctly spelled\")"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word: satjh\n",
            "Candidate Word with probability\n",
            "sath 14108.613414634146\n",
            "sajh 2.196432934278036\n",
            "samjh 20.67153951576062\n",
            "satah 1360.3228481555618\n",
            "sateh 3.4571428571428573\n",
            "The most probable word is sath\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NlSYKVIrJ-v"
      },
      "source": [
        "EXAMPLE 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsvuyER7ogJk",
        "outputId": "7f11b9ab-1d09-4277-f2d5-ead45dec2f3f"
      },
      "source": [
        "wrong_word = \"hiz\"\n",
        "\n",
        "if isMisspelled(unigram, wrong_word): \n",
        "  candidates = generate_candidates(wrong_word, unigram)\n",
        "  get_most_probable(candidates, wrong_word, insert, delete, subsitute, traversal, bigram, count_bigram, unigram)\n",
        "else: \n",
        "  print(\"word is correctly spelled\")"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word: hiz\n",
            "Candidate Word with probability\n",
            "hi 6931.7816858702245\n",
            "hit 17.162912022765\n",
            "hia 27.932513583071202\n",
            "him 23.357240749200546\n",
            "iz 8.596437380104138\n",
            "his 72.22961890979258\n",
            "chiz 687.6\n",
            "hii 73.30705079605762\n",
            "hil 26.666291629162917\n",
            "hin 26.162162162162165\n",
            "aiz 205.6188161281098\n",
            "hik 10.650140318054257\n",
            "ziz 22.333560245064668\n",
            "hir 80.89259075087021\n",
            "hip 6.647703427372348\n",
            "hiv 0.6585923217550275\n",
            "hie 3.7142857142857144\n",
            "uiz 0.585216572504708\n",
            "hid 0.36954481464101363\n",
            "haz 4.323706033743209\n",
            "hez 0.7310344827586206\n",
            "biz 0.3360258481421648\n",
            "hifz 0.004052296805540156\n",
            "fiz 1.3468354430379748\n",
            "hz 0.20520128250801567\n",
            "hoz 2.6984888462461023\n",
            "haiz 0.0015644477917116\n",
            "hizo 0.0\n",
            "diz 0.14500234631628342\n",
            "hij 0.17946990116801437\n",
            "The most probable word is hi\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL5o_7iqrLmg"
      },
      "source": [
        "EXAMPLE 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBBNerzQojBt",
        "outputId": "34ae2ee8-c4be-4ca7-dba8-6016aae8e3db"
      },
      "source": [
        "wrong_word = \"lekiy\"\n",
        "\n",
        "if isMisspelled(unigram, wrong_word): \n",
        "  candidates = generate_candidates(wrong_word, unigram)\n",
        "  get_most_probable(candidates, wrong_word, insert, delete, subsitute, traversal, bigram, count_bigram, unigram)\n",
        "else: \n",
        "  print(\"word is correctly spelled\")"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word: lekiy\n",
            "Candidate Word with probability\n",
            "lekin 15705.539539539539\n",
            "The most probable word is lekin\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqtwq-qCtYoL"
      },
      "source": [
        "Complete Sentence as an Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOZtnSjUpuh4",
        "outputId": "311f4e01-b227-46f5-c4ef-6db4f0ff3741"
      },
      "source": [
        "sentence = \"yaar xyeh saii hai lekiq\" \n",
        "token = sentence.split() \n",
        "new_sent = [] \n",
        "for i in range(len(token)): \n",
        "  if isMisspelled(unigram, token[i]): \n",
        "    candidates = generate_candidates(token[i], unigram)\n",
        "    word = get_most_probable(candidates, token[i], insert, delete, subsitute, traversal, bigram, count_bigram, unigram) \n",
        "    new_sent.append(word)\n",
        "  else: \n",
        "    new_sent.append(token[i]) \n",
        "\n",
        "separator = ' '\n",
        "print(\"Misspelled Sentence:\", sentence)\n",
        "print(\"Corrected Sentence:\", separator.join(new_sent))\n",
        "\n",
        "\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word: xyeh\n",
            "Candidate Word with probability\n",
            "yeh 31762.19257311863\n",
            "The most probable word is yeh\n",
            "\n",
            "\n",
            "Word: saii\n",
            "Candidate Word with probability\n",
            "sai 58.63250454821104\n",
            "sahi 248.77420153503343\n",
            "saif 0.16570771001150747\n",
            "saki 18.650608044901777\n",
            "sahii 0.00012187176983387824\n",
            "sari 37.08876181004475\n",
            "aii 9.47779177391971\n",
            "said 18.548568747067105\n",
            "haii 18.92151522654122\n",
            "sali 1.6255625562556255\n",
            "sami 0.46870717222476016\n",
            "saib 14.43987999076852\n",
            "sadi 51.80807132801502\n",
            "sani 21.47172172172172\n",
            "sii 4.19818260493293\n",
            "sagi 0.14560439560439561\n",
            "naii 2.403403403403403\n",
            "sabi 0.30994691899376875\n",
            "gaii 0.5393772893772893\n",
            "safi 0.2623705408515535\n",
            "sain 1.1961961961961962\n",
            "savi 0.02056672760511883\n",
            "sair 189.19542516161113\n",
            "saini 0.008444502036956207\n",
            "saji 0.35130278526504943\n",
            "saqi 1.2525252525252526\n",
            "sati 0.23049561299502014\n",
            "sais 0.15903614457831325\n",
            "saiu 0.06779661016949153\n",
            "The most probable word is sahi\n",
            "\n",
            "\n",
            "Word: lekiq\n",
            "Candidate Word with probability\n",
            "lekin 15916.824824824826\n",
            "The most probable word is lekin\n",
            "\n",
            "\n",
            "Misspelled Sentence: yaar xyeh saii hai lekiq\n",
            "Corrected Sentence: yaar yeh sahi hai lekin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNvCU-qVp7Mr"
      },
      "source": [
        ""
      ],
      "execution_count": 118,
      "outputs": []
    }
  ]
}